{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5r6Ev24dQFQ",
        "outputId": "61e321a8-2643-4e41-87e8-051ff855c453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmOYyTXidmhJ",
        "outputId": "fa1655a4-0d48-426e-e91a-daefbea01f64"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-pshpkb9h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-pshpkb9h\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=fdb30b442a03a2b978d94f242f4f3839c3b517111d4c5bcc31496f40b5aacbba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e05jnund/wheels/ef/1d/c6/f7e47f1aa1bc9d05c4120d94f90a79cf28603ef343b0dd43ff\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC0CDkCSdt7c",
        "outputId": "34d92ac4-e521-45aa-91bc-74122a1bf00d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_multiplication.cu\n",
        "// vector_multiplication_compare.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <sys/time.h>\n",
        "#include <assert.h>\n",
        "\n",
        "// CUDA Kernel\n",
        "__global__ void mult_vect_gpu(float *x, float *y, float *z, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        z[idx] = x[idx] * y[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CPU Function\n",
        "void mult_vect_cpu(float *x, float *y, float *z, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        z[i] = x[i] * y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Time utility\n",
        "double time_diff(struct timeval start, struct timeval end) {\n",
        "    return (end.tv_sec - start.tv_sec) + (end.tv_usec - start.tv_usec) / 1000000.0;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *x_h, *y_h, *z_h_cpu, *z_h_gpu;\n",
        "    float *x_d, *y_d, *z_d;\n",
        "    int n = 1000000;  // Use a larger n for better timing comparison\n",
        "    size_t size = n * sizeof(float);\n",
        "\n",
        "    // Allocate memory\n",
        "    x_h = (float *)malloc(size);\n",
        "    y_h = (float *)malloc(size);\n",
        "    z_h_cpu = (float *)malloc(size);\n",
        "    z_h_gpu = (float *)malloc(size);\n",
        "\n",
        "    cudaMalloc((void **)&x_d, size);\n",
        "    cudaMalloc((void **)&y_d, size);\n",
        "    cudaMalloc((void **)&z_d, size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        x_h[i] = (float)i;\n",
        "        y_h[i] = (float)(i + 1);\n",
        "    }\n",
        "\n",
        "    // ========== CPU Execution ==========\n",
        "    struct timeval start_cpu, end_cpu;\n",
        "    gettimeofday(&start_cpu, NULL);\n",
        "    mult_vect_cpu(x_h, y_h, z_h_cpu, n);\n",
        "    gettimeofday(&end_cpu, NULL);\n",
        "    double time_cpu = time_diff(start_cpu, end_cpu);\n",
        "\n",
        "    // ========== GPU Execution ==========\n",
        "    cudaMemcpy(x_d, x_h, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(y_d, y_h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int block_size = 256;\n",
        "    int num_blocks = (n + block_size - 1) / block_size;\n",
        "\n",
        "    struct timeval start_gpu, end_gpu;\n",
        "    gettimeofday(&start_gpu, NULL);\n",
        "    mult_vect_gpu<<<num_blocks, block_size>>>(x_d, y_d, z_d, n);\n",
        "    cudaDeviceSynchronize();  // Ensure kernel finishes before timing ends\n",
        "    gettimeofday(&end_gpu, NULL);\n",
        "    double time_gpu = time_diff(start_gpu, end_gpu);\n",
        "\n",
        "    cudaMemcpy(z_h_gpu, z_d, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // ========== Verify Results ==========\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(z_h_cpu[i] == z_h_gpu[i]);\n",
        "    }\n",
        "\n",
        "    // ========== Print Times ==========\n",
        "    printf(\"\\nCPU Time : %lf seconds\\n\", time_cpu);\n",
        "    printf(\"GPU Time : %lf seconds\\n\\n\", time_gpu);\n",
        "\n",
        "    // ========== Print Speedup ==========\n",
        "    double speedup = time_cpu / time_gpu;\n",
        "    printf(\"Speedup: %lf\\n\", speedup);\n",
        "\n",
        "    // ========== Cleanup ==========\n",
        "    free(x_h);\n",
        "    free(y_h);\n",
        "    free(z_h_cpu);\n",
        "    free(z_h_gpu);\n",
        "    cudaFree(x_d);\n",
        "    cudaFree(y_d);\n",
        "    cudaFree(z_d);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf0GPQwRdum8",
        "outputId": "2bda9bf9-247a-4055-e75a-ecd91f6badb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_multiplication.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o vector_multiplication vector_multiplication.cu\n",
        "!./vector_multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNsTDQLrd17b",
        "outputId": "b0c2e6f0-9229-4d3a-e091-e1ca0f01e092"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU Time : 0.004551 seconds\n",
            "GPU Time : 0.000171 seconds\n",
            "\n",
            "Speedup: 26.614035\n"
          ]
        }
      ]
    }
  ]
}