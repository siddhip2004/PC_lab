{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-XQj6VqVD7o",
        "outputId": "b37cc233-dcd2-4c46-f02b-c646a93ade0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Array: [1, 2, 3, 4, 5]\n",
            "CPU Prefix Sum: [1, 3, 6, 10, 15]\n",
            "GPU Prefix Sum: [1, 3, 6, 10, 15]\n",
            "GPU Execution Time: 0.000151 seconds\n"
          ]
        }
      ],
      "source": [
        "cuda_code = r'''\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <cassert>\n",
        "#include <sys/time.h>\n",
        "#include <cmath>\n",
        "\n",
        "#define N 5\n",
        "#define BLOCKSIZE 5\n",
        "\n",
        "// CPU Prefix Sum\n",
        "void PrefixSumCPU(float *hostInput, float *hostOutputCPU) {\n",
        "    hostOutputCPU[0] = hostInput[0];\n",
        "    for (int i = 1; i < N; i++) {\n",
        "        hostOutputCPU[i] = hostOutputCPU[i - 1] + hostInput[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// CUDA Kernel\n",
        "__global__ void PrefixSumKernel(float *deviceInput, float *deviceOutput, int arrayLength, int threadCount) {\n",
        "    __shared__ float tempShared[N];\n",
        "    int tid = threadIdx.x;\n",
        "\n",
        "    if (tid < arrayLength) {\n",
        "        tempShared[tid] = deviceInput[tid];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int offset = 1; offset < arrayLength; offset *= 2) {\n",
        "        float val = 0;\n",
        "        if (tid >= offset)\n",
        "            val = tempShared[tid - offset];\n",
        "        __syncthreads();\n",
        "        tempShared[tid] += val;\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (tid < arrayLength) {\n",
        "        deviceOutput[tid] = tempShared[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Time difference helper\n",
        "double getTimeDiff(timeval start, timeval end) {\n",
        "    return (double)(end.tv_sec - start.tv_sec) + (double)(end.tv_usec - start.tv_usec) / 1e6;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float hostInput[N], hostOutputGPU[N], hostOutputCPU[N];\n",
        "    float *deviceInput, *deviceOutput;\n",
        "\n",
        "    // Initialize host input\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        hostInput[i] = static_cast<float>(i + 1);\n",
        "    }\n",
        "\n",
        "    cudaMalloc((void**)&deviceInput,  N * sizeof(float));\n",
        "    cudaMalloc((void**)&deviceOutput, N * sizeof(float));\n",
        "    cudaMemcpy(deviceInput, hostInput, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 dimBlock(BLOCKSIZE);\n",
        "    dim3 dimGrid(1);\n",
        "\n",
        "    timeval start, end;\n",
        "    gettimeofday(&start, nullptr);\n",
        "    PrefixSumKernel<<<dimGrid, dimBlock>>>(deviceInput, deviceOutput, N, BLOCKSIZE);\n",
        "    cudaDeviceSynchronize();\n",
        "    gettimeofday(&end, nullptr);\n",
        "\n",
        "    double gpuTime = getTimeDiff(start, end);\n",
        "    cudaMemcpy(hostOutputGPU, deviceOutput, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    PrefixSumCPU(hostInput, hostOutputCPU);\n",
        "\n",
        "    // Output formatted results\n",
        "    std::cout << \"Input Array: [\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        std::cout << hostInput[i];\n",
        "        if (i < N - 1) std::cout << \", \";\n",
        "    }\n",
        "    std::cout << \"]\\n\";\n",
        "\n",
        "    std::cout << \"CPU Prefix Sum: [\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        std::cout << hostOutputCPU[i];\n",
        "        if (i < N - 1) std::cout << \", \";\n",
        "    }\n",
        "    std::cout << \"]\\n\";\n",
        "\n",
        "    std::cout << \"GPU Prefix Sum: [\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        std::cout << hostOutputGPU[i];\n",
        "        if (i < N - 1) std::cout << \", \";\n",
        "        assert(fabs(hostOutputCPU[i] - hostOutputGPU[i]) < 1e-5);\n",
        "    }\n",
        "    std::cout << \"]\\n\";\n",
        "\n",
        "    std::cout << \"GPU Execution Time: \" << gpuTime << \" seconds\\n\";\n",
        "\n",
        "    cudaFree(deviceInput);\n",
        "    cudaFree(deviceOutput);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "# Save updated code to file\n",
        "with open(\"prefix_sum_cleaned.cu\", \"w\") as f:\n",
        "    f.write(cuda_code)\n",
        "\n",
        "# Compile for T4 GPU\n",
        "!nvcc -arch=sm_75 prefix_sum_cleaned.cu -o prefix_sum_cleaned\n",
        "\n",
        "# Run it\n",
        "!./prefix_sum_cleaned"
      ]
    }
  ]
}